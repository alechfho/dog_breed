{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math as math\n",
    "import random\n",
    "import time\n",
    "\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from triplet_encoding import *\n",
    "from shared_module import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters\n",
    "- N_ANCHORS determines the number of anchors we find for each breed\n",
    "- ENCODING_STRATEGY dictates the image encoding model and the size of the input vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_ANCHORS = ANCHORS_10\n",
    "ENCODING_STRATEGY = VGG19_4096\n",
    "ENCODING_SIZE = 4096\n",
    "\n",
    "random.seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-processed training file. The training file already contains the anchors and cluster information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N_ANCHORS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-66d28e8a4361>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mINPUT_FILE_PATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./input/labels_train_small'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtraining_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mINPUT_FILE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN_ANCHORS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mENCODING_STRATEGY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdf_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_file_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'anchor'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'N_ANCHORS' is not defined"
     ]
    }
   ],
   "source": [
    "INPUT_FILE_PATH = './input/labels_train_small'\n",
    "\n",
    "training_file_path = get_path(INPUT_FILE_PATH, N_ANCHORS, ENCODING_STRATEGY)\n",
    "\n",
    "df_train = pd.read_csv(training_file_path('anchor'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics about the breeds in dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_train.groupby(['breed']).agg(['count']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breeds and sample of pictures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds = df_train['breed'].unique()\n",
    "\n",
    "display('total number of breeds ' + str(len(breeds)))\n",
    "\n",
    "\n",
    "def sample_by_breed(df_train):\n",
    "    breeds = df_train['breed'].unique()\n",
    "    random.seed()\n",
    "    breed = breeds[random.randint(0, len(breeds) - 1)]\n",
    "    df_breed = df_train.loc[(df_train['breed'] == breed)]\n",
    "    random_index = random.randint(0, (df_breed.shape[0] - 1))\n",
    "    print(breed)\n",
    "    show_img(df_breed.iloc[random_index].id)\n",
    "\n",
    "    \n",
    "def show_img(image_id):\n",
    "    img = Image.open(IMAGE_DIR + '/{name}.jpg'.format(name=image_id))\n",
    "    plt.imshow(img)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "sample_by_breed(df_train)\n",
    "sample_by_breed(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the pre-processed triplets training file\n",
    "## Shuffle the triplets so that we don't just train all of a single breed first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_triplets(df_triplets):\n",
    "    return df_triplets.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df_triplets = pd.read_csv(training_file_path('triplets'))\n",
    "\n",
    "df_triplets = shuffle_triplets(df_triplets)\n",
    "print('Total number of triplets ' + str(df_triplets.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show samples of the triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_triplets(df_triplets):\n",
    "    row = df_triplets.iloc[random.randint(0, df_triplets.shape[0]-1)]\n",
    "    anchor_path = IMAGE_DIR + '/{name}.jpg'.format(name=row['anchor_id'])\n",
    "    img = Image.open(anchor_path)\n",
    "    plt.imshow(img)\n",
    "    plt.title('anchor')\n",
    "    plt.show()\n",
    "    print(anchor_path)\n",
    "    print(row['anchor_type'])\n",
    "    positive_path = IMAGE_DIR + '/{name}.jpg'.format(name=row['positive_id'])\n",
    "    img = Image.open(positive_path)\n",
    "    plt.imshow(img)\n",
    "    plt.title('positive')\n",
    "    plt.show()\n",
    "    print(positive_path)\n",
    "    print(row['positive_type'])\n",
    "    negative_path = IMAGE_DIR + '/{name}.jpg'.format(name=row['negative_id'])\n",
    "    img = Image.open(negative_path)\n",
    "    plt.imshow(img)\n",
    "    plt.title('negative')\n",
    "    plt.show()\n",
    "    print(negative_path)\n",
    "    print(row['negative_type'])\n",
    "\n",
    "show_triplets(df_triplets)\n",
    "show_triplets(df_triplets)\n",
    "show_triplets(df_triplets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_model = input_encoding_model((1, ENCODING_SIZE))\n",
    "training_model = input_training_model((1, ENCODING_SIZE), (1, ENCODING_SIZE), (1, ENCODING_SIZE), encoding_model)\n",
    "training_model.compile(optimizer='adam', loss=triplet_loss, metrics=['accuracy'])\n",
    "training_model.optimizer.lr = 0.00000001\n",
    "\n",
    "def load_triplets(df_triplets):\n",
    "    n_triplets = df_triplets.shape[0]\n",
    "    anchors = np.zeros((n_triplets, 1, ENCODING_SIZE))\n",
    "    pos = np.zeros((n_triplets, 1, ENCODING_SIZE))\n",
    "    negs = np.zeros((n_triplets, 1, ENCODING_SIZE))\n",
    "\n",
    "    i = 0\n",
    "    for i, triplet in df_triplets.iterrows():\n",
    "        anchors[i] = np.loadtxt(triplet['anchor_encoding'])\n",
    "        pos[i] = np.loadtxt(triplet['positive_encoding'])\n",
    "        negs[i] = np.loadtxt(triplet['negative_encoding'])\n",
    "        i = i + 1\n",
    "        if (i % 1000 == 0):\n",
    "            print('Loaded ' + str(i) + ' triplets')\n",
    "    print('Loaded ' + str(n_triplets))\n",
    "    \n",
    "    return anchors, pos, negs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the encoding for the given triplets into memory\n",
    "### Train the model with the whole training set\n",
    "\n",
    "because we use the triplet loss function, we ignore the y_labels, hence we use y_dummies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors, pos, negs = load_triplets(df_triplets)\n",
    "n_triplets = df_triplets.shape[0]\n",
    "y_dummies = np.zeros((n_triplets, 1, n_triplets))\n",
    "\n",
    "\n",
    "training_model.fit(x=[anchors,pos,negs], y=[y_dummies,y_dummies,y_dummies] , batch_size=1024, epochs=20, shuffle=True)\n",
    "\n",
    "df_train_results, total, bad_predictions, accuracy = predict_on_model(df_train, model_encode(encoding_model, ENCODING_SIZE))\n",
    "print('total ' + str(total))\n",
    "print('bad predictions ' + str(bad_predictions))\n",
    "print('accuracy ' + str(accuracy))\n",
    "\n",
    "\n",
    "df_train_results_mismatch = df_train_results.loc[(df_train_results.prediction == False)]\n",
    "df_train_results_mismatch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def triplet_tuple(id_value, breed_value, encoding_value):\n",
    "    return [id_value, breed_value, encoding_value]\n",
    "\n",
    "def create_triplet(anchor_tuple, positive_tuple, negative_tuple):\n",
    "    result = []\n",
    "    for value in anchor_tuple:\n",
    "        result.append(value)\n",
    "    for value in positive_tuple:\n",
    "        result.append(value)\n",
    "    for value in negative_tuple:\n",
    "        result.append(value)\n",
    "    return result\n",
    "\n",
    "def extract_triplets(df_mismatch, df_train):\n",
    "    new_triplets_list = []\n",
    "\n",
    "    for i, bad_pred in df_mismatch.iterrows():\n",
    "        pred_anchors = df_train.loc[(df_train.breed == bad_pred.breed)]\n",
    "        for i, pred_anchor in pred_anchors.iterrows():\n",
    "            anchor = triplet_tuple(pred_anchor['id'], pred_anchor['breed'], pred_anchor['encoding'])\n",
    "            positive = triplet_tuple(bad_pred['id'], bad_pred['breed'], bad_pred['encoding'])\n",
    "            negative = triplet_tuple(bad_pred['prediction_id'], bad_pred['prediction_breed'], bad_pred['prediction_encoding'])\n",
    "            new_triplets_list.append(create_triplet(anchor, positive, negative))\n",
    "#             new_triplets_list.append(create_triplet(positive, anchor, negative))\n",
    "\n",
    "    df_new_triplets = pd.DataFrame(new_triplets_list, columns=['anchor_id', 'anchor_type', 'anchor_encoding', 'positive_id', 'positive_type', 'positive_encoding', 'negative_id', 'negative_type', 'negative_encoding'])\n",
    "    return df_new_triplets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the bad prediction and train the model to recognize these against the corresponding anchors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_triplets = extract_triplets(df_train_results_mismatch, df_train)\n",
    "print(df_new_triplets.shape)\n",
    "df_new_triplets.head()\n",
    "\n",
    "anchors, pos, negs = load_triplets(df_new_triplets)\n",
    "n_triplets = df_new_triplets.shape[0]\n",
    "y_dummies = np.zeros((n_triplets, 1, n_triplets))\n",
    "\n",
    "training_model.fit(x=[anchors,pos,negs], y=[y_dummies,y_dummies,y_dummies] , batch_size=1024, epochs=50, shuffle=True)\n",
    "\n",
    "df_train_results, total, bad_predictions, accuracy = predict_on_model(df_train, model_encode(encoding_model, ENCODING_SIZE))\n",
    "print('total ' + str(total))\n",
    "print('bad predictions ' + str(bad_predictions))\n",
    "print('accuracy ' + str(accuracy))\n",
    "\n",
    "df_train_results_mismatch = df_train_results.loc[(df_train_results.prediction == False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
